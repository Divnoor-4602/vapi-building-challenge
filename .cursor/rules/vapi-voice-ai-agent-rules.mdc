---
description: A comprehensive reference file for Cursor IDE, covering setup, SDK usage, assistant configuration, voice & multilingual support, call/event handling, background messages, hooks, dynamic variables, voice formatting, custom LLM integration (including ngrok guide and tool calling), and a detailed prompting guide.
globs: 
alwaysApply: false
---
# Vapi Voice Agent & Custom LLM Guidelines

## Documentation Links

* **Quickstart Guide**: [https://docs.vapi.ai/quickstart/dashboard](https://docs.vapi.ai/quickstart/dashboard)
* **Web Call Integration**: [https://docs.vapi.ai/documentation/get-started/make-a-web-call](https://docs.vapi.ai/documentation/get-started/make-a-web-call)

### Examples

* **Outbound Sales Example**: [https://docs.vapi.ai/examples/outbound-sales](https://docs.vapi.ai/examples/outbound-sales)
* **Inbound Support Example**: [https://docs.vapi.ai/examples/inbound-support](https://docs.vapi.ai/examples/inbound-support)

### Assistant Customizations

* **Dynamic Variables**: [https://docs.vapi.ai/assistants/dynamic-variables](https://docs.vapi.ai/assistants/dynamic-variables)
* **Multilingual Support**: [https://docs.vapi.ai/customization/multilingual](https://docs.vapi.ai/customization/multilingual)
* **Personalization**: [https://docs.vapi.ai/assistants/personalization](https://docs.vapi.ai/assistants/personalization)
* **Voice Formatting Plan**: [https://docs.vapi.ai/assistants/voice-formatting-plan](https://docs.vapi.ai/assistants/voice-formatting-plan)
* **Background Messages**: [https://docs.vapi.ai/assistants/background-messages](https://docs.vapi.ai/assistants/background-messages)
* **Assistant Hooks**: [https://docs.vapi.ai/assistants/assistant-hooks](https://docs.vapi.ai/assistants/assistant-hooks)
* **Voice Fallback Plan**: [https://docs.vapi.ai/voice-fallback-plan](https://docs.vapi.ai/voice-fallback-plan)

### Custom LLM

* **Using Your Server (Custom LLM)**: [https://docs.vapi.ai/customization/custom-llm/using-your-server](https://docs.vapi.ai/customization/custom-llm/using-your-server)
* **Tool Calling Integration**: [https://docs.vapi.ai/customization/tool-calling-integration](https://docs.vapi.ai/customization/tool-calling-integration)

### SDK Documentation

* **Web SDK**: [https://docs.vapi.ai/sdk/web](https://docs.vapi.ai/sdk/web)
* **Server SDK (Python)**: [https://github.com/VapiAI/server-sdk-python](https://github.com/VapiAI/server-sdk-python)

---

## Installation & Setup

### Web SDK Installation

```bash
# with npm
npm install @vapi-ai/web
# with yarn
yarn add @vapi-ai/web
# with pnpm
pnpm add @vapi-ai/web
```

### SDK Import & Initialization

```javascript
import Vapi from "@vapi-ai/web";

// Initialize with your public key or JWT
const vapi = new Vapi("YOUR_PUBLIC_KEY_OR_JWT");
```

* **Dashboard**: Get public key at [https://dashboard.vapi.ai/account](https://dashboard.vapi.ai/account)
* **JWT Auth**: [https://docs.vapi.ai/customization/jwt-authentication](https://docs.vapi.ai/customization/jwt-authentication)

---

## Assistant Configuration

### Assistant Creation

```javascript
// Persistent Assistant by ID
await vapi.start("79f3XXXX-XXXX-XXXX-XXXX-XXXXXXXXce48");

// Ephemeral Assistant by config object
await vapi.start({
  transcriber: { provider: "deepgram", model: "nova-2", language: "en-US" },
  model: {
    provider: "openai",
    model: "gpt-3.5-turbo",
    messages: [ { role: "system", content: "You are a helpful assistant." } ]
  },
  voice: { provider: "playht", voiceId: "jennifer" },
  name: "My Assistant"
});
```

### Assistant Overrides

Use the second parameter to customize settings or variables at start:

```javascript
const overrides = {
  transcriber: { provider: "deepgram", model: "nova-2", language: "en-US" },
  recordingEnabled: false,
  variableValues: { name: "Alice" }
};
await vapi.start("assistant-id", overrides);
```

---

## Voice & Multilingual Support

### Multilingual Voices

Each TTS provider offers locale-specific voice IDs. Example for Spanish (Azure):

```json
{
  "voice": {
    "provider": "azure",
    "voiceId": "es-ES-ElviraNeural"
  }
}
```

* **Voice docs**: [https://docs.vapi.ai/assistants/voice-formatting-plan](https://docs.vapi.ai/assistants/voice-formatting-plan)

### Transcribers (STT)

Open the Dashboard > Assistants > Transcriber tab to see providers & models; Google & Deepgram provide multilingual models.

---

## Call & Event Management

### Starting Calls

```javascript
const call = await vapi.start("assistant-id");
console.log(call.id, call.orgId, call.createdAt);
```

### Stopping Calls

```javascript
vapi.stop(); // Stops recording & closes connection
```

### Microphone Control

```javascript
const muted = vapi.isMuted();
vapi.setMuted(true);  // Mute
vapi.setMuted(false); // Unmute
```

### Programmatic Speech

```javascript
// Speak a message and end the call afterward
vapi.say("Our time's up, goodbye!", true);
```

---

## Message Handling & Background Messages

### Sending Messages

```javascript
vapi.send({
  type: "add-message",
  message: {
    role: "system",  // "system" | "user" | "assistant" | "tool" | "function"
    content: "User pressed the button."
  }
});
```

### Background Messages Use Cases

* Silent logging of user actions
* Contextual updates without interrupting user flow
* Non-intrusive enhancements

> **Note:** Background messages do not notify the user visibly.

---

## Event Handling

### Essential Event Listeners

```javascript
// Call lifecycle
vapi.on("call-start", () => console.log("Call started."));
vapi.on("call-end",   () => console.log("Call ended."));

// Speech events
vapi.on("speech-start", () => console.log("Speech started."));
vapi.on("speech-end",   () => console.log("Speech ended."));

// Volume level
vapi.on("volume-level", (vol) => console.log(`Volume: ${vol}`));

// Message reception
vapi.on("message", (msg) => console.log("Received message:", msg));

// Error handling
vapi.on("error", (err) => console.error("Vapi error:", err));
```

* **Always** implement error handlers in production.

---

## Assistant Hooks

Automate actions on call events or interruptions.

```json
{
  "hooks": [{
    "on": "call.ending",
    "filters": [{ "type": "oneOf", "key": "call.endedReason", "oneOf": ["pipeline-error"] }],
    "do": [{
      "type": "transfer",
      "destination": { "type": "number", "number": "+1234567890", "callerId": "+1987654321" }
    }]
  }]
}
```

* Use filters and multiple `do` actions as needed.

> **Speech interruption example**:

```json
{
  "hooks": [{
    "on": "assistant.speech.interrupted",
    "do": [{ "type": "say", "exact": ["Sorry about that", "Please continue"] }]
  }]
}
```

---

## Dynamic Variables

Use `{{variable}}` placeholders in any prompt or message.

### Setting Variables via API

```json
{
  "assistantId": "id",
  "assistantOverrides": { "variableValues": { "name": "John" } },
  "customer": { "number": "+1xxxxxxxxxx" },
  "phoneNumberId": "phone-id"
}
```

### Default Variables (UTC-based)

| Variable              | Description               | Example              |
| --------------------- | ------------------------- | -------------------- |
| `{{now}}`             | Current date & time (UTC) | Jan 1, 2024 12:00 PM |
| `{{date}}`            | Current date (UTC)        | Jan 1, 2024          |
| `{{time}}`            | Current time (UTC)        | 12:00 PM             |
| `{{month}}`           | Current month (UTC)       | January              |
| `{{day}}`             | Day of month (UTC)        | 1                    |
| `{{year}}`            | Current year (UTC)        | 2024                 |
| `{{customer.number}}` | Caller phone number       | +1xxxxxxxxxx         |
| `{{customer.X}}`      | Other customer property   |                      |

### Advanced Formatting

Use LiquidJS filters: [https://liquidjs.com/](https://liquidjs.com/)

```liquid
{{"now" | date: "%A, %B %d, %Y, %I:%M %p", "America/Los_Angeles"}}
```

---

## Voice Formatting Plan

Transforms raw text for natural TTS output.

| Step | Function                                 | Description                            |
| :--: | ---------------------------------------- | -------------------------------------- |
|   1  | removeAngleBracketContent                | Removes `<...>` except `<break>`, etc. |
|   2  | removeMarkdownSymbols                    | Strips `_`, `` ` ``, `~`               |
|   3  | removePhrasesInAsterisks                 | Removes `*text*`                       |
|   4  | replaceNewLinesWithPeriods               | `\n` → `.`                             |
|   5  | replaceColonsWithPeriods                 | `:` → `.`                              |
|   6  | formatAcronyms                           | Spaces unknown acronyms                |
|   7  | formatDollarAmounts                      | `$42.50` → words                       |
|   8  | formatEmails                             | `@`→"at", `.`→"dot"                    |
|   9  | formatDates                              | `2023 05 10`→"Wednesday, May 10, 2023" |
|  10  | formatTimes                              | `14:00`→"14"                           |
|  11  | formatDistances/Units/Percentages/Phones | Converts `5km`, `50%`, `123-456-7890`  |
|  12  | formatNumbers                            | Spell negative/decimal numbers         |
|  13  | removeAsterisks                          | Removes all `*`                        |
|  14  | Applying Replacements                    | Custom exact/regex substitutions       |

> **Disable formatting**:  `voice.chunkPlan.formatPlan.enabled = false`

---

## Personalization with User Information

Include customer data by returning dynamic variables or full assistant config from your server.

### Flow

1. Incoming call event delivered to your server endpoint.
2. Server looks up customer by phone number.
3. Return JSON with either:

   * `assistantId` + `assistantOverrides.variableValues`
   * or a full `assistant` config block with customer context.

### Example: Dynamic Variables

```javascript
res.json({
  assistantId: "asst_customersupport",
  assistantOverrides: {
    variableValues: { customerName: customer.name, accountType: customer.tier, joinDate: customer.createdAt }
  }
});
```

### Example: Full Config

```javascript
res.json({
  assistant: {
    name: "Dynamic Support Assistant",
    model: { provider: "openai", model: "gpt-4", messages: [{ role: "system", content: `Helping ${customer.name}, ${customer.tier} member since ${customer.createdAt}` }] },
    voice: { provider: "11labs", voiceId: "shimmer" }
  }
});
```

---

## Custom LLM Integration

### Connecting Your Custom LLM

<details>
<summary>Click to expand setup guide</summary>

**Title:** Connecting Your Custom LLM to Vapi: A Comprehensive Guide
**Slug:** customization/custom-llm/using-your-server

**Prerequisites**

* Vapi account & dashboard access
* OpenAI API key with `gpt-3.5-turbo-instruct`
* Python environment with `pip install openai`
* Ngrok for tunneling
* Code example: [https://github.com/VapiAI/server-side-example-python-flask/blob/main/app/api/custom\_llm.py](https://github.com/VapiAI/server-side-example-python-flask/blob/main/app/api/custom_llm.py)

**Step 1: Local Server**
Create `app.py`:

```python
from flask import Flask, request, jsonify
import openai
app = Flask(__name__)
openai.api_key = "YOUR_OPENAI_API_KEY"

@app.route("/chat/completions", methods=["POST"])
def chat_completions():
    data = request.get_json()
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo-instruct",
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            # include conversation history & user prompt
        ]
    )
    # Format according to Vapi structure
    formatted = { /* ... */ }
    return jsonify(formatted)

if __name__ == "__main__":
    app.run(debug=True, port=5000)
```

**Step 2: Ngrok Tunnel**

```bash
ngrok http 5000
```

Copy `https://<ngrok-id>.ngrok.io`

**Step 3: Configure in Vapi**

* Dashboard > Model > Custom LLM
* Endpoint URL = `https://<ngrok-id>.ngrok.io/chat/completions`
* Save & Test by sending a message

**Communication Flow:**

1. Vapi → POST to ngrok URL
2. Flask endpoint parses & calls OpenAI API
3. Format response & return JSON
4. Vapi displays assistant reply

</details>

---

### Custom LLM Tool Calling Integration

<details>
<summary>Click to expand tool-calling guide</summary>
**Slug:** customization/tool-calling-integration

#### Native LLM Tools

Process streaming SSE chunks from OpenAI to detect `delta.tool_calls` and execute your local functions:

```typescript
// Pseudocode:
for await (const chunk of openAIResponse) {
  if (chunk.choices[0].delta.tool_calls) {
    // accumulate args, call local tool, stream follow-up
  }
  res.write(`data: ${JSON.stringify(chunk)}`);
}
```

#### Vapi-Attached Tools

Detect calls to built-in tools like `transferCall` and emit function call payload back to Vapi:

```typescript
if (funcName === 'transferCall') {
  res.write(`data: ${JSON.stringify({ function_call: { name: 'transferCall', arguments: { destination }}})}`);
  continue;
}
```

#### Custom Tools

Endpoint `/chat/completions/custom-tool` handles toolCallList:

```typescript
app.post('/chat/completions/custom-tool', (req, res) => {
  const list = req.body.message.toolCallList;
  // find toolCall with name `processOrder`
  return res.json({ results: [{ toolCallId: '123', result: 'OK' }] });
});
```

#### cURL Testing Examples

```bash
# Native tool
curl -X POST https://custom-llm-url/chat/completions -d '{"tools":[{"function":{"name":"get_payment_link"}}]}'

# Vapi tool
curl -X POST https://custom-llm-url/chat/completions -d '{"tools":[{"function":{"name":"transferCall"}}],"destination":"555-1234"}'

# Custom tool
curl -X POST https://custom-llm-url/chat/completions/custom-tool -d '{"message":{"toolCallList":[{"id":"123","function":{"name":"processOrder","arguments":{}}}]}}'
```

#### Integrating with Vapi

Two PATCH examples:

1. Without tools (response-only)
2. With tools (`transferCall`, `processOrder`)

See full cURL in source file.

</details>

---

## Prompting Guide

**Slug:** prompting-guide

## Overview

This guide helps you write effective prompts for Voice AI assistants. Learn how to design, test, and refine prompts to get the best results from your agents. Use these strategies to improve your agent's reliability, success rate, and user experience.

## Why prompt engineering matters

Prompt engineering is the art of crafting clear, actionable instructions for AI agents. Well-designed prompts:

* Guide the AI to produce accurate, relevant, and context-sensitive outputs
* Improve the agent's ability to handle requests without human intervention
* Increase your overall success rate

Poor prompts can lead to ambiguous or incorrect results, limiting the agent's utility.

## How to measure success

Your "success rate" is the percentage of requests your agent handles from start to finish without human intervention. The more complex your use case, the more you'll need to experiment and iterate on your prompt to improve this rate.

## The process

Follow a structured approach to prompt engineering:

<Steps>
  <Step title="Design">
    Craft your initial prompt, considering the specific task, context, and desired outcome. Clear and detailed prompts help guide the AI in understanding your needs.
  </Step>
  <Step title="Test">
    Run the prompt through the AI. Evaluate if the response aligns with your expectations and meets the intended goal. Testing helps identify potential gaps in clarity or structure.
  </Step>
  <Step title="Refine">
    Adjust the prompt based on test results. Reword, add detail, or change phrasing to avoid ambiguity and improve the response.
  </Step>
  <Step title="Repeat">
    Iterate on the process, testing and refining until the AI's output is accurate and relevant. Your success rate should improve with each cycle.
  </Step>
</Steps>

## Principles of effective prompts

### Organize prompts into sections

Break down system prompts into clear sections, each focused on a specific aspect:

* **Identity:** Define the agent's persona and role
* **Style:** Set stylistic guidelines (conciseness, tone, humor)
* **Response guidelines:** Specify formatting, question limits, or structure
* **Task & goals:** Outline objectives and steps

**Example:**

```md wordWrap
[Identity]
You are a helpful and knowledgeable virtual assistant for a travel booking platform.

[Style]
- Be informative and comprehensive.
- Maintain a professional and polite tone.
- Be concise, as you are currently operating as a Voice Conversation.

[Response Guideline]
- Present dates in a clear format (e.g., January 15, 2024).
- Offer up to three travel options based on user preferences.

[Task]
1. Greet the user and inquire about their desired travel destination.
2. Ask about travel dates and preferences (e.g., budget, interests).
3. Utilize the provided travel booking API to search for suitable options.
4. Present the top three options to the user, highlighting key features.
```

### Break down complex tasks

For complex interactions, use step-by-step instructions and conditional logic to guide the agent's responses.

**Example:**

```md wordWrap
[Task]
1. Welcome the user to the technical support service.
2. Inquire about the nature of the technical issue.
3. If the issue is related to software, ask about the specific software and problem details.
4. If the issue is hardware-related, gather information about the device and symptoms.
5. Based on the collected information, provide troubleshooting steps or escalate to a human technician if necessary.
```

### Control response timing

Explicitly indicate when the agent should wait for the user's response before proceeding.

**Example:**

```md wordWrap
[Task]
1. Inform the user about the purpose of the call.
2. Ask for the user's name and account information.
<wait for user response>
3. Inquire about the reason for the call and offer assistance options.
```

### Integrate tools and APIs

Specify when and how the agent should use external tools or APIs. Reference tools by their designated names and describe their functions.

**Example:**

```md wordWrap
[Task]
3. If the user wants to know about something, use the get_data function with the parameter 'query', which will contain the user's question to initiate the process.
4. Guide the user through the password reset steps provided by the API.
```

### Silent transfers

If the AI determines that the user needs to be transferred, do not send any text response back to the user. Instead, silently call the appropriate tool for transferring the call. This ensures a seamless user experience and avoids confusion.

### Include fallback and error handling

Always include fallback options and error-handling mechanisms in your prompts. This ensures the agent can gracefully handle unexpected user inputs or system errors.

**Example:**

```md wordWrap
[Error Handling]
If the customer's response is unclear, ask clarifying questions. If you encounter any issues, inform the customer politely and ask to repeat.
```

## Additional tips

* **Iterate as much as possible.** AI is driven by experimentation and iteration—refining prompts through trial and error will help you achieve more precise, relevant, and effective responses.
* **Use Markdown formatting:** Structure your content for clarity and easy scanning.
* **Emotional prompting:** Use expressive language to shape the AI's tone and create more engaging, relatable responses. For example, "Can you tell me a cozy bedtime story that's warm and comforting?"
* **Add voice realism:** Incorporate natural speech elements like stuttering, hesitations, and pauses:

  * **Stuttering:** Use repeated letters or sounds (e.g., "I-I-I don't know").
  * **Hesitations:** Add fillers like "uh," "um," or "well" (e.g., "I was, uh, thinking about it").
  * **Pauses:** Use ellipses ("...") to indicate a pause (e.g., "I... I don't know how to say this").
  * **Emotional emphasis:** Use capital letters, exclamation marks, or ellipses to reflect tone (e.g., "I can't... I just can't believe it!").

## Common issues

**Numbers sound robotic?**

* Spell out numbers in prompts for more natural-sounding speech.

**How to make assistants sound more human-like?**

* Add personality and tone to the assistant. For example:

  ```md wordWrap
  - Tone: conversational, spartan, use less corporate jargon
  - Act as Iva, a sales agent who is a human being and has real feelings.
  ```

## Example: Appointment setter prompt

```md wordWrap
[Role]
You're Susan, an AI assistant for xxx. Your primary task is to interact with the customer, ask questions, and gather information for appointment booking.

[Context]
You're engaged with the customer to book an appointment. Stay focused on this context and provide relevant information. Once connected to a customer, proceed to the Conversation Flow section. Do not invent information not drawn from the context. Answer only questions related to the context.

[Response Handling]
When asking any question from the 'Conversation Flow' section, evaluate the customer's response to determine if it qualifies as a valid answer. Use context awareness to assess relevance and appropriateness. If the response is valid, proceed to the next relevant question or instructions. Avoid infinite loops by moving forward when a clear answer cannot be obtained.

[Warning]
Do not modify or attempt to correct user input parameters or user input, Pass them directly into the function or tool as given.

[Response Guidelines]
Keep responses brief.
Ask one question at a time, but combine related questions where appropriate.
Maintain a calm, empathetic, and professional tone.
Answer only the question posed by the user.
Begin responses with direct answers, without introducing additional data.
If unsure or data is unavailable, ask specific clarifying questions instead of a generic response.
Present dates in a clear format (e.g., January Twenty Four) and Do not mention years in dates.
Present time in a clear format (e.g. Four Thirty PM) like: eleven pee em.
Speak dates gently using English words instead of numbers.
Never say the word 'function' nor 'tools' nor the name of the Available functions.
Never say ending the call.
If you think you are about to transfer the call, do not send any text response. Simply trigger the tool silently. This is crucial for maintaining a smooth call experience.

[Error Handling]
If the customer's response is unclear, ask clarifying questions. If you encounter any issues, inform the customer politely and ask to repeat.

[Conversation Flow]
1. Ask: "You made a recent inquiry, can I ask you a few quick follow-up questions?"
- if response indicates interest: Proceed to step 2.
- if response indicates no interest: Proceed to 'Call Closing'.
2. Ask: "You connected with us in regard to an auto accident. Is this something you would still be interested in pursuing?"
- If response indicates interest: Proceed to step 3.
- If response indicates no interest: Proceed to 'Call Closing'.
3. Ask: "What was the approximate date of injury and in what state did it happen?"
- Proceed to step 4.
4. Ask: "On a scale of 1 to 3, would you rate the injury? 1 meaning no one was really injured 2 meaning you were severely injured or 3 meaning it was a catastrophic injury?"
- If response indicates injury level above 1: Proceed to step 5.
- If response indicates no injury or minor injury: Proceed to 'Call Closing'.
5. Ask: "Can you describe in detail your injury and if anyone else in the car was injured and their injuries?"
- Proceed to step 6.
6. Ask: "Did the police issue a ticket?"
- Proceed to step 7.
7. Ask: "Did the police say whose fault it was and was the accident your fault?"
- If response indicates not at fault(e.g. "no", "not my fault", etc.):Proceed to step 8.
- If response indicates at fault(e.g. "yes", "my fault", etc.): Proceed to 'Call Closing'.
8. Ask: "Do you have an attorney representing you in this case?" 
- If response confirms no attorney: Proceed to step 9.
- If response indicates they have an attorney: Proceed to 'Call Closing'.
9. Ask: "Would you like to speak with an attorney now or book an appointment?"
- If the response indicates "speak now": Proceed to 'Transfer Call'
- if the response indicates "book appointment": Proceed to 'Book Appointment'
10. After receiving response, proceed to the 'Call Closing' section.

[Book Appointment]
1. Ask: "To make sure I have everything correct, could you please confirm your first name for me?"
2. Ask: "And your last name, please?"
3. We're going to send you the appointment confirmation by text, can you provide the best mobile number for you to receive a sms or text?" 
4. Trigger the 'fetchSlots' tool and map the result to {{available_slots}}.
5. Ask: "I have two slots available, {{available_slots}}. Would you be able to make one of those times work?"
6. <wait for user response>
7. Set the {{selectedSlot}} variable to the user's response.
8. If {{selectedSlot}} is one of the available slots (positive response): 
   - Trigger the 'bookSlot' tool with the {{selectedSlot}}.
   - <wait for 'bookSlot' tool result>
   - Inform the user of the result of the 'bookSlot' tool.
   - Proceed to the 'Call Closing' section.
9. If {{selectedSlot}} is not one of the available slots (negative response):
   - Proceed to the 'Suggest Alternate Slot' section.

[Suggest Alternate Slot]
1. Ask: "If none of these slots work for you, could you please suggest a different time that suits you?"
2. <wait for user response>
3. Set the {{selectedSlot}} variable to the user's response.
4. Trigger the 'bookSlot' tool with the {{selectedSlot}}.
5. <wait for 'bookSlot' tool result>
6. If the {{selectedSlot}} is available:
   - Inform the user of the result.
7. If the {{selectedSlot}} is not available:
   - Trigger the 'fetchSlots' tool, provide the user {{selectedSlot}} as input and map the result to {{available_slots}}.
   - Say: "That time is unavailable but here are some other times we can do {{available_slots}}."
   - Ask: "Do either of those times work?"
   - <wait for user response>
   - If the user agrees to one of the new suggested slots:
        - Set the {{selectedSlot}} variable to the user's response.
        - Trigger the 'bookSlot' tool with the {{selectedSlot}}.
        - <wait for 'bookSlot' tool result>
        - Inform the user of the result.
   - If the user rejects the new suggestions:
        - Proceed to the 'Last Message' section.

[Last Message]
 - Respond: "Looks like this is taking longer than expected. Let me have one of our appointment specialists get back to you to make this process simple and easy." 
- Proceed to the 'Call Closing' section.

[Call Closing]
- Trigger the endCall Function.
```

## Additional resources


* [learnprompting.org](https://learnprompting.org)
* [promptingguide.ai](https://promptingguide.ai)
* [OpenAI's guide to prompt engineering](https://platform.openai.com/docs/guides/prompt-engineering)

## Resources & Examples

* **Vapi Web SDK**: [https://www.npmjs.com/package/@vapi-ai/web](https://www.npmjs.com/package/@vapi-ai/web)
* **Quickstart Guide**: [https://docs.vapi.ai/quickstart/dashboard](https://docs.vapi.ai/quickstart/dashboard)
* **JWT Auth**: [https://docs.vapi.ai/customization/jwt-authentication](https://docs.vapi.ai/customization/jwt-authentication)
* **OpenAI API Reference**: [https://platform.openai.com/docs/api-reference/making-requests](https://platform.openai.com/docs/api-reference/making-requests)
* **Dynamic Variables**: [https://docs.vapi.ai/assistants/dynamic-variables](https://docs.vapi.ai/assistants/dynamic-variables)
* **Prompt Engineering**: [https://learnprompting.org](https://learnprompting.org), [https://promptingguide.ai](https://promptingguide.ai), [https://platform.openai.com/docs/guides/prompt-engineering](https://platform.openai.com/docs/guides/prompt-engineering)

---

*End of Vapi Voice Agent & Custom LLM Guidelines for Cursor IDE*
